{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.zju.edu.cn/pypi/simple\n",
      "Could not fetch URL https://mirrors.zju.edu.cn/pypi/simple/beautifulsoup4/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='mirrors.zju.edu.cn', port=443): Max retries exceeded with url: /pypi/simple/beautifulsoup4/ (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))) - skipping\n",
      "Could not fetch URL https://mirrors.zju.edu.cn/pypi/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='mirrors.zju.edu.cn', port=443): Max retries exceeded with url: /pypi/simple/pip/ (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))) - skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/beautifulsoup4/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/beautifulsoup4/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/beautifulsoup4/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/beautifulsoup4/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/beautifulsoup4/\n",
      "ERROR: Could not find a version that satisfies the requirement beautifulsoup4 (from versions: none)\n",
      "ERROR: No matching distribution found for beautifulsoup4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.zju.edu.cn/pypi/simple\n",
      "Could not fetch URL https://mirrors.zju.edu.cn/pypi/simple/halo/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='mirrors.zju.edu.cn', port=443): Max retries exceeded with url: /pypi/simple/halo/ (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))) - skipping\n",
      "Could not fetch URL https://mirrors.zju.edu.cn/pypi/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='mirrors.zju.edu.cn', port=443): Max retries exceeded with url: /pypi/simple/pip/ (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))) - skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/halo/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/halo/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/halo/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/halo/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1131)'))': /pypi/simple/halo/\n",
      "ERROR: Could not find a version that satisfies the requirement halo (from versions: none)\n",
      "ERROR: No matching distribution found for halo\n"
     ]
    }
   ],
   "source": [
    "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org beautifulsoup4\n",
    "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org halo\n",
    "\n",
    "\n",
    "!pip install --index-url https://pypi.org/simple/ openai\n",
    "!pip install --index-url https://pypi.org/simple/ pypdf2\n",
    "!pip install --index-url https://pypi.org/simple/ pyyaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple/\n",
      "Collecting chardet\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 30.7/199.4 kB 77.0 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 30.7/199.4 kB 77.0 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 41.0/199.4 kB 93.7 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 41.0/199.4 kB 93.7 kB/s eta 0:00:02\n",
      "   ------------ -------------------------- 61.4/199.4 kB 113.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 71.7/199.4 kB 122.9 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 71.7/199.4 kB 122.9 kB/s eta 0:00:02\n",
      "   ------------------ -------------------- 92.2/199.4 kB 137.9 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 112.6/199.4 kB 159.8 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 112.6/199.4 kB 159.8 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 122.9/199.4 kB 160.2 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 143.4/199.4 kB 170.4 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 153.6/199.4 kB 173.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 174.1/199.4 kB 187.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 199.4/199.4 kB 212.3 kB/s eta 0:00:00\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --index-url https://pypi.org/simple/ chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\GenAI-literature\\[Here] Our Authoring Tool for literature summary\\extraction\\extraction.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GenAI-literature/%5BHere%5D%20Our%20Authoring%20Tool%20for%20literature%20summary/extraction/extraction.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GenAI-literature/%5BHere%5D%20Our%20Authoring%20Tool%20for%20literature%20summary/extraction/extraction.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m time, sleep\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GenAI-literature/%5BHere%5D%20Our%20Authoring%20Tool%20for%20literature%20summary/extraction/extraction.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhalo\u001b[39;00m \u001b[39mimport\u001b[39;00m Halo\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\openai\\__init__.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39maiohttp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[39mdel\u001b[39;00m sys\u001b[39m.\u001b[39mmodules[\u001b[39m\"\u001b[39m\u001b[39mpkg_resources\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_resources\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Audio,\n\u001b[0;32m     21\u001b[0m     ChatCompletion,\n\u001b[0;32m     22\u001b[0m     Completion,\n\u001b[0;32m     23\u001b[0m     Customer,\n\u001b[0;32m     24\u001b[0m     Deployment,\n\u001b[0;32m     25\u001b[0m     Edit,\n\u001b[0;32m     26\u001b[0m     Embedding,\n\u001b[0;32m     27\u001b[0m     Engine,\n\u001b[0;32m     28\u001b[0m     ErrorObject,\n\u001b[0;32m     29\u001b[0m     File,\n\u001b[0;32m     30\u001b[0m     FineTune,\n\u001b[0;32m     31\u001b[0m     FineTuningJob,\n\u001b[0;32m     32\u001b[0m     Image,\n\u001b[0;32m     33\u001b[0m     Model,\n\u001b[0;32m     34\u001b[0m     Moderation,\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39merror\u001b[39;00m \u001b[39mimport\u001b[39;00m APIError, InvalidRequestError, OpenAIError\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m VERSION\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\openai\\api_resources\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_resources\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m Audio  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_resources\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_completion\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatCompletion  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_resources\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompletion\u001b[39;00m \u001b[39mimport\u001b[39;00m Completion  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\openai\\api_resources\\audio.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, List\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m api_requestor, util\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_resources\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mabstract\u001b[39;00m \u001b[39mimport\u001b[39;00m APIResource\n\u001b[0;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAudio\u001b[39;00m(APIResource):\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\openai\\api_requestor.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlencode, urlsplit, urlunsplit\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maiohttp\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m):\n\u001b[0;32m     27\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\requests\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m charset_normalizer_version\n\u001b[0;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     charset_normalizer_version \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32md:\\Download\\anaconda\\envs\\openai\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[39m=\u001b[39m Union[\u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mos.PathLike[str]\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmd\u001b[39;00m \u001b[39mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39mimport\u001b[39;00m warn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from time import time, sleep\n",
    "from halo import Halo\n",
    "import textwrap\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     file operations\n",
    "\n",
    "def save_file(filepath, content):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "def save_yaml(filepath, data):\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        yaml.dump(data, file, allow_unicode=True)\n",
    "\n",
    "def open_yaml(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     API functions\n",
    "\n",
    "def chatbot(conversation, model=\"gpt-4-0613\", temperature=0):\n",
    "    max_retry = 7\n",
    "    retry = 0\n",
    "    while True:\n",
    "        try:\n",
    "            spinner = Halo(text='Thinking...', spinner='dots')\n",
    "            spinner.start()\n",
    "            \n",
    "            response = openai.ChatCompletion.create(model=model, messages=conversation, temperature=temperature)\n",
    "            text = response['choices'][0]['message']['content']\n",
    "\n",
    "            spinner.stop()\n",
    "            \n",
    "            return text, response['usage']['total_tokens']\n",
    "        except Exception as oops:\n",
    "            print(f'\\n\\nError communicating with OpenAI: \"{oops}\"')\n",
    "            if 'maximum context length' in str(oops):\n",
    "                a = conversation.pop(0)\n",
    "                print('\\n\\n DEBUG: Trimming oldest message')\n",
    "                continue\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                print(f\"\\n\\nExiting due to excessive errors in API: {oops}\")\n",
    "                exit(1)\n",
    "            print(f'\\n\\nRetrying in {2 ** (retry - 1) * 5} seconds...')\n",
    "            sleep(2 ** (retry - 1) * 5)\n",
    "\n",
    "def chat_print(text):\n",
    "    formatted_lines = [textwrap.fill(line, width=120, initial_indent='    ', subsequent_indent='    ') for line in text.split('\\n')]\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    print('\\n\\n\\nCHATBOT:\\n\\n%s' % formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    openai.api_key = open_file('key_openai.txt').strip()\n",
    "    paper = open_file('input.txt')\n",
    "    if len(paper) > 22000:\n",
    "        paper = paper[0:22000]\n",
    "    ALL_MESSAGES = [{'role':'system', 'content': paper}]\n",
    "    while True:\n",
    "        # get user input\n",
    "        text = input('\\n\\n\\nUSER:\\n\\n')\n",
    "        if text == '':\n",
    "            # empty submission, probably on accident\n",
    "            continue\n",
    "        ALL_MESSAGES.append({'role': 'user', 'content': text})\n",
    "        \n",
    "        # get response\n",
    "        response, tokens = chatbot(ALL_MESSAGES)\n",
    "        if tokens >= 7800:\n",
    "            a = ALL_MESSAGES.pop(1)\n",
    "        chat_print(response)\n",
    "        ALL_MESSAGES.append({'role': 'assistant', 'content': response})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from time import time, sleep\n",
    "from halo import Halo\n",
    "import textwrap\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     file operations\n",
    "\n",
    "def save_file(filepath, content):\n",
    "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(content)\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "def save_yaml(filepath, data):\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        yaml.dump(data, file, allow_unicode=True)\n",
    "\n",
    "def open_yaml(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     API functions\n",
    "\n",
    "def chatbot(conversation, model=\"gpt-4-0613\", temperature=0):\n",
    "    max_retry = 7\n",
    "    retry = 0\n",
    "    while True:\n",
    "        try:\n",
    "            spinner = Halo(text='Thinking...', spinner='dots')\n",
    "            spinner.start()\n",
    "            \n",
    "            response = openai.ChatCompletion.create(model=model, messages=conversation, temperature=temperature)\n",
    "            text = response['choices'][0]['message']['content']\n",
    "\n",
    "            spinner.stop()\n",
    "            \n",
    "            return text, response['usage']['total_tokens']\n",
    "        except Exception as oops:\n",
    "            print(f'\\n\\nError communicating with OpenAI: \"{oops}\"')\n",
    "            if 'maximum context length' in str(oops):\n",
    "                a = conversation.pop(0)\n",
    "                print('\\n\\n DEBUG: Trimming oldest message')\n",
    "                continue\n",
    "            retry += 1\n",
    "            if retry >= max_retry:\n",
    "                print(f\"\\n\\nExiting due to excessive errors in API: {oops}\")\n",
    "                exit(1)\n",
    "            print(f'\\n\\nRetrying in {2 ** (retry - 1) * 5} seconds...')\n",
    "            sleep(2 ** (retry - 1) * 5)\n",
    "\n",
    "def chat_print(text):\n",
    "    formatted_lines = [textwrap.fill(line, width=120, initial_indent='    ', subsequent_indent='    ') for line in text.split('\\n')]\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    print('\\n\\n\\nCHATBOT:\\n\\n%s' % formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    openai.api_key = open_file('key_openai.txt').strip()\n",
    "    paper = open_file('input.txt')\n",
    "    if len(paper) > 22000:\n",
    "        paper = paper[0:22000]\n",
    "    ALL_MESSAGES = [{'role':'system', 'content': paper}]\n",
    "    while True:\n",
    "        # get user input\n",
    "        text = input('\\n\\n\\nUSER:\\n\\n')\n",
    "        if text == '':\n",
    "            # empty submission, probably on accident\n",
    "            continue\n",
    "        ALL_MESSAGES.append({'role': 'user', 'content': text})\n",
    "        \n",
    "        # get response\n",
    "        response, tokens = chatbot(ALL_MESSAGES)\n",
    "        if tokens >= 7800:\n",
    "            a = ALL_MESSAGES.pop(1)\n",
    "        chat_print(response)\n",
    "        ALL_MESSAGES.append({'role': 'assistant', 'content': response})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
